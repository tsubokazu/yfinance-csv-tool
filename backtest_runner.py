#!/usr/bin/env python3
"""
åŒ…æ‹¬çš„ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆå®Ÿè¡Œã‚¹ã‚¯ãƒªãƒ—ãƒˆ

æŒ‡å®šã—ãŸæœŸé–“ãƒ»éŠ˜æŸ„ãƒ»é–“éš”ã§ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œã—ã€
AIåˆ¤æ–­ç”¨ã®ãƒ‡ãƒ¼ã‚¿ï¼ˆãƒãƒ£ãƒ¼ãƒˆç”»åƒä»˜ãï¼‰ã‚’æ™‚ç³»åˆ—ã§ç”Ÿæˆã—ã¾ã™ã€‚
"""

import argparse
import logging
from datetime import datetime, timedelta
from pathlib import Path
from typing import List, Dict, Optional
import json
import pandas as pd
from tqdm import tqdm

from minute_decision_engine import MinuteDecisionEngine


def setup_logging(log_level: str = "INFO"):
    """ãƒ­ã‚°è¨­å®š"""
    log_dir = Path("logs")
    log_dir.mkdir(exist_ok=True)
    
    logging.basicConfig(
        level=getattr(logging, log_level.upper()),
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
        handlers=[
            logging.StreamHandler(),
            logging.FileHandler(log_dir / 'backtest.log')
        ]
    )


def generate_backtest_timeline(
    start_datetime: datetime,
    end_datetime: datetime,
    interval_minutes: int,
    market_hours_only: bool = True
) -> List[datetime]:
    """
    ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆç”¨ã®æ™‚åˆ»ãƒªã‚¹ãƒˆã‚’ç”Ÿæˆ
    
    Args:
        start_datetime: é–‹å§‹æ—¥æ™‚
        end_datetime: çµ‚äº†æ—¥æ™‚
        interval_minutes: é–“éš”ï¼ˆåˆ†ï¼‰
        market_hours_only: å–å¼•æ™‚é–“ã®ã¿ï¼ˆ9:00-15:00ï¼‰
        
    Returns:
        æ™‚åˆ»ãƒªã‚¹ãƒˆ
    """
    timeline = []
    current_time = start_datetime
    
    while current_time <= end_datetime:
        # å¸‚å ´æ™‚é–“ãƒã‚§ãƒƒã‚¯
        if market_hours_only:
            hour = current_time.hour
            minute = current_time.minute
            
            # å¹³æ—¥ã®9:00-15:00ã®ã¿
            if (current_time.weekday() < 5 and  # å¹³æ—¥
                ((hour == 9 and minute >= 0) or  # 9:00ä»¥é™
                 (10 <= hour <= 14) or           # 10:00-14:59
                 (hour == 15 and minute == 0))):  # 15:00ã¾ã§
                timeline.append(current_time)
        else:
            timeline.append(current_time)
            
        current_time += timedelta(minutes=interval_minutes)
    
    return timeline


def run_backtest(
    symbol: str,
    start_datetime: datetime,
    end_datetime: datetime,
    interval_minutes: int = 1,
    market_hours_only: bool = True,
    enable_charts: bool = True,
    output_dir: str = "backtest_results"
) -> Dict:
    """
    ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
    
    Args:
        symbol: éŠ˜æŸ„ã‚³ãƒ¼ãƒ‰
        start_datetime: é–‹å§‹æ—¥æ™‚
        end_datetime: çµ‚äº†æ—¥æ™‚
        interval_minutes: åˆ¤æ–­é–“éš”ï¼ˆåˆ†ï¼‰
        market_hours_only: å–å¼•æ™‚é–“ã®ã¿
        enable_charts: ãƒãƒ£ãƒ¼ãƒˆç”Ÿæˆæœ‰åŠ¹
        output_dir: å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
        
    Returns:
        ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆçµæœã‚µãƒãƒªãƒ¼
    """
    print(f"ğŸ¯ ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆé–‹å§‹: {symbol}")
    print(f"  æœŸé–“: {start_datetime} ï½ {end_datetime}")
    print(f"  é–“éš”: {interval_minutes}åˆ†")
    print(f"  ãƒãƒ£ãƒ¼ãƒˆç”Ÿæˆ: {'æœ‰åŠ¹' if enable_charts else 'ç„¡åŠ¹'}")
    
    # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
    output_path = Path(output_dir)
    output_path.mkdir(exist_ok=True)
    
    # æ™‚åˆ»ãƒªã‚¹ãƒˆç”Ÿæˆ
    timeline = generate_backtest_timeline(
        start_datetime, end_datetime, interval_minutes, market_hours_only
    )
    
    print(f"  ç”Ÿæˆãƒ‡ãƒ¼ã‚¿ãƒã‚¤ãƒ³ãƒˆæ•°: {len(timeline)}ä»¶")
    
    if len(timeline) == 0:
        print("âŒ æœ‰åŠ¹ãªæ™‚åˆ»ãŒã‚ã‚Šã¾ã›ã‚“")
        return {}
    
    # ã‚¨ãƒ³ã‚¸ãƒ³åˆæœŸåŒ–
    engine = MinuteDecisionEngine(enable_chart_generation=enable_charts)
    
    results = []
    failed_count = 0
    
    try:
        # é€²æ—ãƒãƒ¼ã‚’è¡¨ç¤ºã—ã¦ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
        for timestamp in tqdm(timeline, desc="ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆé€²è¡Œä¸­"):
            try:
                # åˆ¤æ–­ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
                decision_data = engine.get_backtest_decision_data(symbol, timestamp)
                
                # çµæœã‚’è¨˜éŒ²
                result = {
                    'timestamp': timestamp.isoformat(),
                    'symbol': symbol,
                    'current_price': decision_data.current_price.current_price,
                    'price_change_percent': decision_data.current_price.price_change_percent,
                    'volume_ratio': decision_data.current_price.volume_ratio,
                    
                    # ãƒ†ã‚¯ãƒ‹ã‚«ãƒ«æŒ‡æ¨™ï¼ˆä¸»è¦ãªã‚‚ã®ï¼‰
                    'ma20_daily': decision_data.technical_indicators.daily.moving_averages.ma20,
                    'ma50_daily': decision_data.technical_indicators.daily.moving_averages.ma50,
                    'atr14_daily': decision_data.technical_indicators.daily.atr14,
                    'vwap_60m': decision_data.technical_indicators.hourly_60.vwap.daily,
                    
                    # ãƒãƒ£ãƒ¼ãƒˆç”»åƒãƒ‘ã‚¹
                    'chart_images': {}
                }
                
                # ãƒãƒ£ãƒ¼ãƒˆç”»åƒæƒ…å ±ã‚’è¿½åŠ 
                if decision_data.chart_images:
                    for timeframe in ['weekly', 'daily', 'hourly_60', 'minute_15', 'minute_5', 'minute_1']:
                        chart_data = getattr(decision_data.chart_images, timeframe, None)
                        if chart_data:
                            result['chart_images'][timeframe] = chart_data.imagePath
                
                results.append(result)
                
                # å€‹åˆ¥ã®è©³ç´°ãƒ‡ãƒ¼ã‚¿ã‚‚ä¿å­˜ï¼ˆJSONï¼‰
                if len(results) % 10 == 0:  # 10ä»¶ã”ã¨ã«è©³ç´°ãƒ‡ãƒ¼ã‚¿ä¿å­˜
                    detail_file = output_path / f"detail_{symbol}_{timestamp.strftime('%Y%m%d_%H%M%S')}.json"
                    with open(detail_file, 'w', encoding='utf-8') as f:
                        f.write(decision_data.to_json())
                
            except Exception as e:
                logging.error(f"ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼ ({timestamp}): {e}")
                failed_count += 1
                continue
    
    finally:
        engine.close()
    
    # çµæœã‚µãƒãƒªãƒ¼ä½œæˆ
    summary = {
        'symbol': symbol,
        'start_datetime': start_datetime.isoformat(),
        'end_datetime': end_datetime.isoformat(),
        'interval_minutes': interval_minutes,
        'total_datapoints': len(timeline),
        'successful_datapoints': len(results),
        'failed_datapoints': failed_count,
        'success_rate': len(results) / len(timeline) * 100 if timeline else 0,
        'results': results
    }
    
    # çµæœã‚’ä¿å­˜
    timestamp_str = datetime.now().strftime('%Y%m%d_%H%M%S')
    
    # ã‚µãƒãƒªãƒ¼JSON
    summary_file = output_path / f"backtest_summary_{symbol}_{timestamp_str}.json"
    with open(summary_file, 'w', encoding='utf-8') as f:
        json.dump(summary, f, indent=2, ensure_ascii=False)
    
    # CSVå½¢å¼ã®ã‚µãƒãƒªãƒ¼
    if results:
        df = pd.DataFrame(results)
        csv_file = output_path / f"backtest_data_{symbol}_{timestamp_str}.csv"
        df.to_csv(csv_file, index=False, encoding='utf-8')
        
        print(f"\nğŸ“Š ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆå®Œäº†!")
        print(f"  æˆåŠŸ: {len(results)}/{len(timeline)}ä»¶ ({summary['success_rate']:.1f}%)")
        print(f"  å¤±æ•—: {failed_count}ä»¶")
        print(f"\nğŸ’¾ å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«:")
        print(f"  ã‚µãƒãƒªãƒ¼: {summary_file}")
        print(f"  CSVãƒ‡ãƒ¼ã‚¿: {csv_file}")
        
        # ä¾¡æ ¼çµ±è¨ˆ
        prices = [r['current_price'] for r in results]
        print(f"\nğŸ“ˆ ä¾¡æ ¼çµ±è¨ˆ:")
        print(f"  æœ€é«˜å€¤: Â¥{max(prices):,.0f}")
        print(f"  æœ€å®‰å€¤: Â¥{min(prices):,.0f}")
        print(f"  å¹³å‡å€¤: Â¥{sum(prices)/len(prices):,.0f}")
    
    return summary


def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    parser = argparse.ArgumentParser(description='åŒ…æ‹¬çš„ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ')
    parser.add_argument('--symbol', '-s', required=True,
                       help='éŠ˜æŸ„ã‚³ãƒ¼ãƒ‰ (ä¾‹: 7203.T)')
    parser.add_argument('--start', '-st', required=True,
                       help='é–‹å§‹æ—¥æ™‚ (YYYY-MM-DD HH:MM)')
    parser.add_argument('--end', '-ed', required=True,
                       help='çµ‚äº†æ—¥æ™‚ (YYYY-MM-DD HH:MM)')
    parser.add_argument('--interval', '-i', type=int, default=5,
                       help='åˆ¤æ–­é–“éš”ï¼ˆåˆ†ã€ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 5åˆ†ï¼‰')
    parser.add_argument('--all-hours', action='store_true',
                       help='24æ™‚é–“ï¼ˆå¸‚å ´æ™‚é–“å¤–ã‚‚å«ã‚€ï¼‰')
    parser.add_argument('--no-charts', action='store_true',
                       help='ãƒãƒ£ãƒ¼ãƒˆç”Ÿæˆã‚’ç„¡åŠ¹åŒ–')
    parser.add_argument('--output', '-o', default='backtest_results',
                       help='å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª')
    parser.add_argument('--verbose', '-v', action='store_true',
                       help='è©³ç´°ãƒ­ã‚°')
    
    args = parser.parse_args()
    
    # ãƒ­ã‚°è¨­å®š
    log_level = "DEBUG" if args.verbose else "INFO"
    setup_logging(log_level)
    
    # æ—¥æ™‚ãƒ‘ãƒ¼ã‚¹
    try:
        start_datetime = datetime.strptime(args.start, '%Y-%m-%d %H:%M')
        end_datetime = datetime.strptime(args.end, '%Y-%m-%d %H:%M')
    except ValueError:
        print("âŒ æ—¥æ™‚ã®å½¢å¼ãŒæ­£ã—ãã‚ã‚Šã¾ã›ã‚“ã€‚YYYY-MM-DD HH:MMå½¢å¼ã§æŒ‡å®šã—ã¦ãã ã•ã„ã€‚")
        return
    
    if start_datetime >= end_datetime:
        print("âŒ é–‹å§‹æ—¥æ™‚ã¯çµ‚äº†æ—¥æ™‚ã‚ˆã‚Šå‰ã§ã‚ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚")
        return
    
    print("ğŸš€ ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ")
    print("=" * 60)
    
    # ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
    summary = run_backtest(
        symbol=args.symbol,
        start_datetime=start_datetime,
        end_datetime=end_datetime,
        interval_minutes=args.interval,
        market_hours_only=not args.all_hours,
        enable_charts=not args.no_charts,
        output_dir=args.output
    )
    
    if summary:
        print("\nâœ… ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆãŒæ­£å¸¸ã«å®Œäº†ã—ã¾ã—ãŸ")
        print(f"\nğŸ¯ æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—:")
        print(f"  1. ç”Ÿæˆã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã‚’ç¢ºèª: {args.output}/")
        print(f"  2. AIåˆ¤æ–­ã‚·ã‚¹ãƒ†ãƒ ã«åˆ¤æ–­ãƒ‡ãƒ¼ã‚¿ã‚’é€ä¿¡")
        print(f"  3. å–å¼•ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å®Ÿè¡Œ")
    else:
        print("\nâŒ ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆã«å¤±æ•—ã—ã¾ã—ãŸ")


if __name__ == "__main__":
    main()