#!/usr/bin/env python3
"""
AI(LLMã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ)ç”¨ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§ç”Ÿæˆã‚¹ã‚¯ãƒªãƒ—ãƒˆ

ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆçµæœã‹ã‚‰ã€AIã«æ¸¡ã™ã¹ããƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§ã‚’ç”Ÿæˆã—ã¾ã™ã€‚
"""

import argparse
import json
import os
from pathlib import Path
from typing import Dict, List
from datetime import datetime


def find_latest_backtest(result_dir: str = "backtest_results") -> Dict:
    """
    æœ€æ–°ã®ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆçµæœã‚’æ¤œç´¢
    
    Args:
        result_dir: ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆçµæœãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
        
    Returns:
        æœ€æ–°ã®ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆçµæœè¾æ›¸
    """
    result_path = Path(result_dir)
    if not result_path.exists():
        raise FileNotFoundError(f"ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆçµæœãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {result_dir}")
    
    # ã‚µãƒãƒªãƒ¼ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œç´¢
    summary_files = list(result_path.glob("backtest_summary_*.json"))
    if not summary_files:
        raise FileNotFoundError("ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆçµæœãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
    
    # æœ€æ–°ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å–å¾—ï¼ˆãƒ•ã‚¡ã‚¤ãƒ«åã®ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã§ã‚½ãƒ¼ãƒˆï¼‰
    latest_file = max(summary_files, key=lambda f: f.stat().st_mtime)
    
    with open(latest_file, 'r', encoding='utf-8') as f:
        return json.load(f)


def generate_ai_filelist(backtest_result: Dict, output_file: str = "ai_filelist.json") -> Dict:
    """
    AIç”¨ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§ã‚’ç”Ÿæˆ
    
    Args:
        backtest_result: ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆçµæœ
        output_file: å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«å
        
    Returns:
        AIç”¨ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§è¾æ›¸
    """
    symbol = backtest_result['symbol']
    start_time = backtest_result['start_datetime']
    end_time = backtest_result['end_datetime']
    
    ai_filelist = {
        "metadata": {
            "generated_at": datetime.now().isoformat(),
            "symbol": symbol,
            "backtest_period": f"{start_time} to {end_time}",
            "total_datapoints": backtest_result['total_datapoints'],
            "successful_datapoints": backtest_result['successful_datapoints'],
            "success_rate": backtest_result['success_rate']
        },
        "data_files": {
            "summary_json": None,
            "csv_data": None,
            "detail_files": []
        },
        "chart_images": {},
        "trading_decisions": []
    }
    
    # ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹è¨­å®š
    timestamp_str = datetime.fromisoformat(start_time).strftime('%Y%m%d_%H%M%S')
    ai_filelist["data_files"]["summary_json"] = f"backtest_results/backtest_summary_{symbol}_{timestamp_str}.json"
    ai_filelist["data_files"]["csv_data"] = f"backtest_results/backtest_data_{symbol}_{timestamp_str}.csv"
    
    # è©³ç´°ãƒ•ã‚¡ã‚¤ãƒ«ã®æ¤œç´¢
    detail_pattern = f"backtest_results/detail_{symbol}_*.json"
    detail_files = list(Path(".").glob(detail_pattern.replace("backtest_results/", "backtest_results/")))
    ai_filelist["data_files"]["detail_files"] = [str(f) for f in detail_files]
    
    # å„æ™‚åˆ»ã®ãƒãƒ£ãƒ¼ãƒˆç”»åƒã¨åˆ¤æ–­ãƒ‡ãƒ¼ã‚¿ã‚’æ•´ç†
    for i, result in enumerate(backtest_result['results']):
        timestamp = result['timestamp']
        decision_data = {
            "timestamp": timestamp,
            "datapoint_index": i + 1,
            "price_data": {
                "current_price": result['current_price'],
                "price_change_percent": result['price_change_percent'],
                "volume_ratio": result['volume_ratio']
            },
            "technical_indicators": {
                "ma20_daily": result['ma20_daily'],
                "ma50_daily": result['ma50_daily'],
                "atr14_daily": result['atr14_daily'],
                "vwap_60m": result['vwap_60m']
            },
            "chart_images": result.get('chart_images', {}),
            "ai_decision": None,  # AIã®åˆ¤æ–­çµæœã‚’è¨˜éŒ²ã™ã‚‹å ´æ‰€
            "trading_action": None  # å®Ÿéš›ã®å–å¼•ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚’è¨˜éŒ²ã™ã‚‹å ´æ‰€
        }
        
        ai_filelist["trading_decisions"].append(decision_data)
        
        # ãƒãƒ£ãƒ¼ãƒˆç”»åƒã®å­˜åœ¨ç¢ºèª
        for timeframe, image_path in result.get('chart_images', {}).items():
            if Path(image_path).exists():
                if timeframe not in ai_filelist["chart_images"]:
                    ai_filelist["chart_images"][timeframe] = []
                ai_filelist["chart_images"][timeframe].append({
                    "timestamp": timestamp,
                    "path": image_path,
                    "exists": True
                })
    
    # ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§ã‚’ä¿å­˜
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(ai_filelist, f, indent=2, ensure_ascii=False)
    
    return ai_filelist


def print_file_summary(ai_filelist: Dict):
    """AIç”¨ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§ã®ã‚µãƒãƒªãƒ¼ã‚’è¡¨ç¤º"""
    metadata = ai_filelist["metadata"]
    
    print("ğŸ¤– AI(LLMã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ)ç”¨ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§")
    print("=" * 60)
    print(f"éŠ˜æŸ„: {metadata['symbol']}")
    print(f"æœŸé–“: {metadata['backtest_period']}")
    print(f"ãƒ‡ãƒ¼ã‚¿ãƒã‚¤ãƒ³ãƒˆæ•°: {metadata['successful_datapoints']}/{metadata['total_datapoints']} ({metadata['success_rate']:.1f}%)")
    print(f"ç”Ÿæˆæ—¥æ™‚: {metadata['generated_at']}")
    
    print(f"\nğŸ“Š ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«:")
    print(f"  ã‚µãƒãƒªãƒ¼: {ai_filelist['data_files']['summary_json']}")
    print(f"  CSVãƒ‡ãƒ¼ã‚¿: {ai_filelist['data_files']['csv_data']}")
    print(f"  è©³ç´°ãƒ•ã‚¡ã‚¤ãƒ«: {len(ai_filelist['data_files']['detail_files'])}ä»¶")
    
    print(f"\nğŸ–¼ï¸  ãƒãƒ£ãƒ¼ãƒˆç”»åƒ:")
    for timeframe, images in ai_filelist["chart_images"].items():
        print(f"  {timeframe}: {len(images)}æš")
    
    total_images = sum(len(images) for images in ai_filelist["chart_images"].values())
    print(f"  åˆè¨ˆ: {total_images}æš")
    
    print(f"\nğŸ¯ åˆ¤æ–­ãƒ‡ãƒ¼ã‚¿ãƒã‚¤ãƒ³ãƒˆ:")
    for i, decision in enumerate(ai_filelist["trading_decisions"][:3]):  # æœ€åˆã®3ä»¶ã®ã¿è¡¨ç¤º
        print(f"  {i+1}. {decision['timestamp']} - Â¥{decision['price_data']['current_price']:,.0f} ({decision['price_data']['price_change_percent']:+.2f}%)")
    
    if len(ai_filelist["trading_decisions"]) > 3:
        print(f"  ... ä»–{len(ai_filelist['trading_decisions']) - 3}ä»¶")


def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    parser = argparse.ArgumentParser(description='AIç”¨ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§ç”Ÿæˆ')
    parser.add_argument('--result-dir', '-r', default='backtest_results',
                       help='ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆçµæœãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª')
    parser.add_argument('--output', '-o', default='ai_filelist.json',
                       help='å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«å')
    parser.add_argument('--latest-only', action='store_true',
                       help='æœ€æ–°ã®ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆçµæœã®ã¿ä½¿ç”¨')
    
    args = parser.parse_args()
    
    try:
        print("ğŸ” ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆçµæœã‚’æ¤œç´¢ä¸­...")
        
        if args.latest_only:
            # æœ€æ–°ã®ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆçµæœã®ã¿
            backtest_result = find_latest_backtest(args.result_dir)
            print(f"âœ… æœ€æ–°ã®ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆçµæœã‚’ç™ºè¦‹: {backtest_result['symbol']}")
        else:
            # æŒ‡å®šã•ã‚ŒãŸãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆçµæœï¼ˆä»Šå›ã¯æœ€æ–°ã‚’ä½¿ç”¨ï¼‰
            backtest_result = find_latest_backtest(args.result_dir)
            print(f"âœ… ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆçµæœã‚’èª­ã¿è¾¼ã¿: {backtest_result['symbol']}")
        
        print("ğŸ“ AIç”¨ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§ã‚’ç”Ÿæˆä¸­...")
        ai_filelist = generate_ai_filelist(backtest_result, args.output)
        
        print(f"ğŸ’¾ ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§ã‚’ä¿å­˜: {args.output}")
        print_file_summary(ai_filelist)
        
        print(f"\nğŸš€ æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—:")
        print(f"  1. {args.output} ã‚’AIã‚·ã‚¹ãƒ†ãƒ ã«èª­ã¿è¾¼ã¾ã›ã‚‹")
        print(f"  2. å„æ™‚åˆ»ã®ãƒãƒ£ãƒ¼ãƒˆç”»åƒã‚’AIã«åˆ†æã•ã›ã‚‹")
        print(f"  3. åˆ¤æ–­çµæœã‚’ ai_decision ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã«è¨˜éŒ²ã™ã‚‹")
        print(f"  4. å–å¼•ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚’å®Ÿè¡Œã™ã‚‹")
        
    except Exception as e:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼: {e}")
        return 1
    
    return 0


if __name__ == "__main__":
    exit(main())