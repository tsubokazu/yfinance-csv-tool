#!/usr/bin/env python3
"""
æ™‚é–“è¶³åˆ¥ãƒãƒ£ãƒ¼ãƒˆåˆ†æã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚·ã‚¹ãƒ†ãƒ 

å„æ™‚é–“è¶³ã®æ›´æ–°é »åº¦ã«åŸºã¥ã„ã¦ã€ãƒãƒ£ãƒ¼ãƒˆåˆ†æçµæœã‚’åŠ¹ç‡çš„ã«ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ»ç®¡ç†ã™ã‚‹
"""

import json
import logging
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, Any, Optional, Tuple
from dataclasses import dataclass, asdict

logger = logging.getLogger(__name__)


@dataclass
class TimeframeAnalysis:
    """æ™‚é–“è¶³åˆ¥åˆ†æçµæœ"""
    timeframe: str
    last_updated: datetime
    analysis_result: Dict[str, Any]
    next_update_time: datetime
    
    def to_dict(self) -> Dict[str, Any]:
        """è¾æ›¸å½¢å¼ã«å¤‰æ›"""
        return {
            'timeframe': self.timeframe,
            'last_updated': self.last_updated.isoformat(),
            'analysis_result': self.analysis_result,
            'next_update_time': self.next_update_time.isoformat()
        }
    
    @classmethod
    def from_dict(cls, data: Dict[str, Any]) -> 'TimeframeAnalysis':
        """è¾æ›¸ã‹ã‚‰å¾©å…ƒ"""
        return cls(
            timeframe=data['timeframe'],
            last_updated=datetime.fromisoformat(data['last_updated']),
            analysis_result=data['analysis_result'],
            next_update_time=datetime.fromisoformat(data['next_update_time'])
        )


class ChartAnalysisCache:
    """
    æ™‚é–“è¶³åˆ¥ãƒãƒ£ãƒ¼ãƒˆåˆ†æã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼
    
    å„æ™‚é–“è¶³ã®æ›´æ–°é »åº¦ã«åŸºã¥ã„ã¦ã€åŠ¹ç‡çš„ã«ãƒãƒ£ãƒ¼ãƒˆåˆ†æçµæœã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã™ã‚‹
    """
    
    def __init__(self, cache_dir: str = "chart_analysis_cache"):
        self.cache_dir = Path(cache_dir)
        self.cache_dir.mkdir(exist_ok=True)
        
        # æ™‚é–“è¶³åˆ¥è¨­å®š
        self.timeframe_config = {
            'weekly': {
                'update_interval_minutes': 7 * 24 * 60,  # 1é€±é–“
                'update_trigger': 'monday_open',  # æœˆæ›œæ—¥ã®å¸‚å ´ã‚ªãƒ¼ãƒ—ãƒ³æ™‚
                'analysis_focus': [
                    'long_term_trend_direction',
                    'major_support_resistance',
                    'investor_sentiment',
                    'weekly_momentum',
                    'long_term_moving_averages'
                ]
            },
            'daily': {
                'update_interval_minutes': 24 * 60,  # 1æ—¥
                'update_trigger': 'market_open',  # å¸‚å ´ã‚ªãƒ¼ãƒ—ãƒ³æ™‚
                'analysis_focus': [
                    'medium_term_trend',
                    'daily_moving_averages',
                    'volume_analysis',
                    'daily_patterns',
                    'gap_analysis'
                ]
            },
            'hourly_60': {
                'update_interval_minutes': 60,  # 1æ™‚é–“
                'update_trigger': 'hourly',
                'analysis_focus': [
                    'short_term_trend',
                    'vwap_position',
                    'hourly_momentum',
                    'intraday_support_resistance',
                    'volume_profile'
                ]
            },
            'minute_15': {
                'update_interval_minutes': 15,
                'update_trigger': 'quarter_hourly',
                'analysis_focus': [
                    'entry_timing_signals',
                    'short_term_support_resistance',
                    'breakout_confirmation',
                    'micro_trend_changes'
                ]
            },
            'minute_5': {
                'update_interval_minutes': 5,
                'update_trigger': 'five_minute',
                'analysis_focus': [
                    'immediate_price_action',
                    'breakout_validation',
                    'quick_reversal_signals',
                    'scalping_opportunities'
                ]
            },
            'minute_1': {
                'update_interval_minutes': 1,
                'update_trigger': 'every_minute',
                'analysis_focus': [
                    'execution_timing',
                    'tick_analysis',
                    'immediate_market_response',
                    'order_flow_signals'
                ]
            }
        }
    
    def get_cache_file_path(self, symbol: str) -> Path:
        """ã‚·ãƒ³ãƒœãƒ«åˆ¥ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹"""
        return self.cache_dir / f"{symbol}_chart_analysis.json"
    
    def load_cache(self, symbol: str) -> Dict[str, TimeframeAnalysis]:
        """ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿"""
        cache_file = self.get_cache_file_path(symbol)
        
        if not cache_file.exists():
            return {}
        
        try:
            with open(cache_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            cache = {}
            for timeframe, analysis_data in data.items():
                cache[timeframe] = TimeframeAnalysis.from_dict(analysis_data)
            
            return cache
            
        except Exception as e:
            logger.warning(f"ã‚­ãƒ£ãƒƒã‚·ãƒ¥èª­ã¿è¾¼ã¿å¤±æ•—: {e}")
            return {}
    
    def save_cache(self, symbol: str, cache: Dict[str, TimeframeAnalysis]) -> None:
        """ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜"""
        cache_file = self.get_cache_file_path(symbol)
        
        try:
            data = {}
            for timeframe, analysis in cache.items():
                data[timeframe] = analysis.to_dict()
            
            with open(cache_file, 'w', encoding='utf-8') as f:
                json.dump(data, f, indent=2, ensure_ascii=False)
                
        except Exception as e:
            logger.error(f"ã‚­ãƒ£ãƒƒã‚·ãƒ¥ä¿å­˜å¤±æ•—: {e}")
    
    def calculate_next_update_time(self, timeframe: str, current_time: datetime) -> datetime:
        """æ¬¡å›æ›´æ–°æ™‚åˆ»ã‚’è¨ˆç®—"""
        config = self.timeframe_config[timeframe]
        interval_minutes = config['update_interval_minutes']
        
        if timeframe == 'weekly':
            # æœˆæ›œæ—¥ã®å¸‚å ´ã‚ªãƒ¼ãƒ—ãƒ³ï¼ˆ9:00ï¼‰ã‚’è¨ˆç®—
            days_until_monday = (7 - current_time.weekday()) % 7
            if days_until_monday == 0 and current_time.hour < 9:
                # ä»Šæ—¥ãŒæœˆæ›œæ—¥ã§9æ™‚å‰ã®å ´åˆã¯ä»Šæ—¥ã®9æ™‚
                next_update = current_time.replace(hour=9, minute=0, second=0, microsecond=0)
            else:
                # æ¬¡ã®æœˆæ›œæ—¥ã®9æ™‚
                next_update = current_time + timedelta(days=days_until_monday)
                next_update = next_update.replace(hour=9, minute=0, second=0, microsecond=0)
        
        elif timeframe == 'daily':
            # ç¿Œæ—¥ã®å¸‚å ´ã‚ªãƒ¼ãƒ—ãƒ³ï¼ˆ9:00ï¼‰
            if current_time.hour < 9:
                # ä»Šæ—¥ã®9æ™‚å‰ã®å ´åˆã¯ä»Šæ—¥ã®9æ™‚
                next_update = current_time.replace(hour=9, minute=0, second=0, microsecond=0)
            else:
                # ç¿Œæ—¥ã®9æ™‚
                next_update = current_time + timedelta(days=1)
                next_update = next_update.replace(hour=9, minute=0, second=0, microsecond=0)
        
        else:
            # åˆ†è¶³ã®å ´åˆã¯æ¬¡ã®å¢ƒç•Œæ™‚åˆ»ã‚’ç›´æ¥è¨ˆç®—
            if timeframe == 'hourly_60':
                # æ¬¡ã®æ™‚é–“ã®å¢ƒç•Œï¼ˆ00åˆ†ï¼‰
                next_hour = current_time.hour + 1
                if next_hour >= 24:
                    next_update = (current_time + timedelta(days=1)).replace(hour=0, minute=0, second=0, microsecond=0)
                else:
                    next_update = current_time.replace(hour=next_hour, minute=0, second=0, microsecond=0)
                    
            elif timeframe == 'minute_15':
                # æ¬¡ã®15åˆ†å¢ƒç•Œï¼ˆ0, 15, 30, 45åˆ†ï¼‰
                current_minute = current_time.minute
                next_15_minute = ((current_minute // 15) + 1) * 15
                
                if next_15_minute >= 60:
                    next_hour = current_time.hour + 1
                    if next_hour >= 24:
                        next_update = (current_time + timedelta(days=1)).replace(hour=0, minute=0, second=0, microsecond=0)
                    else:
                        next_update = current_time.replace(hour=next_hour, minute=0, second=0, microsecond=0)
                else:
                    next_update = current_time.replace(minute=next_15_minute, second=0, microsecond=0)
                    
            elif timeframe == 'minute_5':
                # æ¬¡ã®5åˆ†å¢ƒç•Œï¼ˆ0, 5, 10, 15, 20...åˆ†ï¼‰
                current_minute = current_time.minute
                next_5_minute = ((current_minute // 5) + 1) * 5
                
                if next_5_minute >= 60:
                    next_hour = current_time.hour + 1
                    if next_hour >= 24:
                        next_update = (current_time + timedelta(days=1)).replace(hour=0, minute=0, second=0, microsecond=0)
                    else:
                        next_update = current_time.replace(hour=next_hour, minute=0, second=0, microsecond=0)
                else:
                    next_update = current_time.replace(minute=next_5_minute, second=0, microsecond=0)
                    
            elif timeframe == 'minute_1':
                # æ¬¡ã®1åˆ†å¢ƒç•Œ
                next_minute = current_time.minute + 1
                if next_minute >= 60:
                    next_hour = current_time.hour + 1
                    if next_hour >= 24:
                        next_update = (current_time + timedelta(days=1)).replace(hour=0, minute=0, second=0, microsecond=0)
                    else:
                        next_update = current_time.replace(hour=next_hour, minute=0, second=0, microsecond=0)
                else:
                    next_update = current_time.replace(minute=next_minute, second=0, microsecond=0)
        
        return next_update
    
    def needs_update(self, timeframe: str, current_time: datetime, cached_analysis: Optional[TimeframeAnalysis]) -> bool:
        """æ›´æ–°ãŒå¿…è¦ã‹ã©ã†ã‹ã‚’åˆ¤å®š"""
        if cached_analysis is None:
            return True
        
        # æ¬¡å›æ›´æ–°æ™‚åˆ»ã‚’éãã¦ã„ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
        return current_time >= cached_analysis.next_update_time
    
    def get_timeframes_to_update(self, symbol: str, current_time: datetime) -> Tuple[Dict[str, TimeframeAnalysis], list]:
        """
        æ›´æ–°ãŒå¿…è¦ãªæ™‚é–“è¶³ã¨æ—¢å­˜ã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’å–å¾—
        
        Returns:
            Tuple[cached_analysis, timeframes_to_update]
        """
        cached_analysis = self.load_cache(symbol)
        timeframes_to_update = []
        
        for timeframe in self.timeframe_config.keys():
            cached = cached_analysis.get(timeframe)
            
            if self.needs_update(timeframe, current_time, cached):
                timeframes_to_update.append(timeframe)
                logger.info(f"ğŸ“ˆ {timeframe} ãƒãƒ£ãƒ¼ãƒˆåˆ†æã®æ›´æ–°ãŒå¿…è¦")
            else:
                logger.info(f"â™»ï¸ {timeframe} ãƒãƒ£ãƒ¼ãƒˆåˆ†æã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰ä½¿ç”¨ (æ¬¡å›æ›´æ–°: {cached.next_update_time})")
        
        return cached_analysis, timeframes_to_update
    
    def update_analysis(self, symbol: str, timeframe: str, analysis_result: Dict[str, Any], current_time: datetime) -> None:
        """åˆ†æçµæœã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«æ›´æ–°"""
        cached_analysis = self.load_cache(symbol)
        
        next_update_time = self.calculate_next_update_time(timeframe, current_time)
        
        cached_analysis[timeframe] = TimeframeAnalysis(
            timeframe=timeframe,
            last_updated=current_time,
            analysis_result=analysis_result,
            next_update_time=next_update_time
        )
        
        self.save_cache(symbol, cached_analysis)
        logger.info(f"âœ… {timeframe} ãƒãƒ£ãƒ¼ãƒˆåˆ†æçµæœã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ä¿å­˜ (æ¬¡å›æ›´æ–°: {next_update_time})")
    
    def get_analysis_focus(self, timeframe: str) -> list:
        """æ™‚é–“è¶³åˆ¥ã®åˆ†æãƒ•ã‚©ãƒ¼ã‚«ã‚¹é …ç›®ã‚’å–å¾—"""
        return self.timeframe_config[timeframe]['analysis_focus']
    
    def get_all_cached_analysis(self, symbol: str) -> Dict[str, Dict[str, Any]]:
        """å…¨æ™‚é–“è¶³ã®åˆ†æçµæœã‚’çµ±åˆã—ã¦å–å¾—"""
        cached_analysis = self.load_cache(symbol)
        
        result = {}
        for timeframe, analysis in cached_analysis.items():
            result[timeframe] = analysis.analysis_result
        
        return result
    
    def clear_cache(self, symbol: str) -> None:
        """æŒ‡å®šéŠ˜æŸ„ã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ã‚¯ãƒªã‚¢"""
        cache_file = self.get_cache_file_path(symbol)
        if cache_file.exists():
            cache_file.unlink()
            logger.info(f"ğŸ—‘ï¸ {symbol} ã®ãƒãƒ£ãƒ¼ãƒˆåˆ†æã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ã‚¯ãƒªã‚¢")
    
    def get_cache_status(self, symbol: str, current_time: datetime) -> Dict[str, Dict[str, Any]]:
        """ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã®çŠ¶æ…‹ã‚’å–å¾—"""
        cached_analysis = self.load_cache(symbol)
        
        status = {}
        for timeframe in self.timeframe_config.keys():
            cached = cached_analysis.get(timeframe)
            
            if cached:
                needs_update = self.needs_update(timeframe, current_time, cached)
                time_until_update = cached.next_update_time - current_time
                
                status[timeframe] = {
                    'has_cache': True,
                    'last_updated': cached.last_updated.isoformat(),
                    'next_update': cached.next_update_time.isoformat(),
                    'needs_update': needs_update,
                    'time_until_update_minutes': time_until_update.total_seconds() / 60,
                    'analysis_items': len(cached.analysis_result)
                }
            else:
                status[timeframe] = {
                    'has_cache': False,
                    'needs_update': True
                }
        
        return status